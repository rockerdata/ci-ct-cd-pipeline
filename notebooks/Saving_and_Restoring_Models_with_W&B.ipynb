{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bEmjBYewiCEc"
      },
      "source": [
        "In this notebook, I'll show you how to save and restore models with Weights and Biases.\n",
        "\n",
        "W&B lets you save everything you need to reproduce your models - weights, architecture, predictions, code to a safe place in the cloud.\n",
        "\n",
        "This is useful because you donâ€™t have to re-train your models, you can simply view their performance days, weeks, or even a few months later. Before you're ready to deploy, you can compare the performance of all the models you trained in the previous months and restore the best performing one."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zHcBma6Li01T"
      },
      "source": [
        "# Train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBGdf7nciyl5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "# define hyperparameters\n",
        "defaults=dict(\n",
        "    dropout = 0.2,\n",
        "    hidden_layer_size = 128,\n",
        "    layer_1_size = 16,\n",
        "    layer_2_size = 32,\n",
        "    learn_rate = 0.01,\n",
        "    decay = 1e-6,\n",
        "    momentum = 0.9,\n",
        "    epochs = 5,\n",
        "    )\n",
        "\n",
        "wandb.login(key='f8fcf3355333e0c4f01595461dc68e14557e483c')\n",
        "# initialize a new wandb run\n",
        "wandb.init(project=\"github_actions_wandb_aws_ec2\", config=defaults)\n",
        "config = wandb.config\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "labels=[\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
        "        \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
        "\n",
        "img_width=28\n",
        "img_height=28\n",
        "\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "\n",
        "# reshape input data\n",
        "X_train = X_train.reshape(X_train.shape[0], img_width, img_height, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_width, img_height, 1)\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "sgd = SGD(lr=config.learn_rate, decay=config.decay, momentum=config.momentum,\n",
        "                            nesterov=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QksXtohLktQa"
      },
      "outputs": [],
      "source": [
        "# %wandb\n",
        "# build model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(config.layer_1_size, (5, 5), activation='relu',\n",
        "                            input_shape=(img_width, img_height,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(config.layer_2_size, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(config.dropout))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(config.hidden_layer_size, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# compile and train model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "model.fit(X_train, y_train,  validation_data=(X_test, y_test), epochs=config.epochs,\n",
        "    callbacks=[WandbCallback(data_type=\"image\", labels=labels)])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eDp1goVbjK6r"
      },
      "source": [
        "# Save a model\n",
        "\n",
        "There are two ways to save a file to associate with a run.\n",
        "1. Use wandb.save(filename).\n",
        "2. Put a file in the wandb run directory, and it will get uploaded at the end of the run.\n",
        "\n",
        "If you want to sync files as they're being written, you can specify a filename or glob in wandb.save.\n",
        "\n",
        "See the docs for [frequently asked questions](https://docs.wandb.com/library/save#common-questions) about saving and restoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kj4vShIjLQ9"
      },
      "outputs": [],
      "source": [
        "# \"model.h5\" is saved in wandb.run.dir & will be uploaded at the end of training\n",
        "model.save(os.path.join(wandb.run.dir, \"model.h5\"))\n",
        "\n",
        "# Save a model file manually from the current directory:\n",
        "wandb.save('model.h5')\n",
        "\n",
        "# Save all files that currently exist containing the substring \"ckpt\":\n",
        "wandb.save('../logs/*ckpt*')\n",
        "\n",
        "# Save any files starting with \"checkpoint\" as they're written to:\n",
        "wandb.save(os.path.join(wandb.run.dir, \"checkpoint*\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P_dpK2SHjIlu"
      },
      "source": [
        "# Restore a model\n",
        "\n",
        "Restore a file, such as a model checkpoint, into your local run folder to access in your script.\n",
        "\n",
        "Common use cases:\n",
        "- restore the model architecture or weights generated by past runs\n",
        "- resume training from the last checkpoint in the case of failure (see the section on resuming for crucial details)\n",
        "\n",
        "See [the restore docs](https://docs.wandb.com/library/restore) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LB6j3O-jIsd"
      },
      "outputs": [],
      "source": [
        "# restore the model file \"model.h5\" from a specific run by user \"lavanyashukla\"\n",
        "# in project \"save_and_restore\" from run \"10pr4joa\"\n",
        "best_model = wandb.restore('model.h5', run_path=\"lavanyashukla/save_and_restore/10pr4joa\")\n",
        "\n",
        "# use the \"name\" attribute of the returned object\n",
        "# if your framework expects a filename, e.g. as in Keras\n",
        "model.load_weights(best_model.name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
